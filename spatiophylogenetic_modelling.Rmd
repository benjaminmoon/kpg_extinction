---
title: "Spatiophylogenetic modelling: the end-Cretaceous extinction"
...

# Introduction

The aim of this part of the project is to use occurrence data of bivalves from across the Cretaceousâ€“Palaeogene boundary to reconstruct extinction prevalence and potential drivers of this.

## Project environment ##


```{r renv_init, eval = FALSE}
renv::restore()
```

*renv*, used above, sets up a *project environment* that stores the packages and versions used to make the project work. The idea of this is to enable you to go back to this after some time and get the project working again, no matter what's changed or been updated in the meantime. Similarly, send the project to a collaborator and they can set things up to be working quickly and easily without having to search through packages to install. I've already *initialized* this project, to get things going on your computer should a matter of opening R in this filter. *renv* will then install itself and any packages needed into its own library.

```{r packages}
library(jsonlite)
library(ggthemes)
library(mapproj)
library(rnaturalearth)
library(sf)
library(tidyverse)
library(viridis)
```

## Useful background and sites ##

I'm rather opinionated about code and formatting. I think it's generally better to be strict about the packages you use and how you write the code. I tend to use *tidyverse* style and formatting, which has [a guide](https://r4ds.had.co.nz/index.html) written by Hadley Wickham, who's created some of the most used R packages. Google have a [style guide](https://google.github.io/styleguide/Rguide.html) for writing R code that I recommend following, but as a guide can and should be changed to meet your needs.

I use *piping* a lot. This means passing the result of one function as the first argument of the next line. R has a native version shown as `|>`, but this is rather new (version 4.1.0). *tidyverse* and package *magrittr* has had a different version for while that looks like `%>%` and is probably the better to use, so you might see that online more often.

This guide is written in [R Markdown](https://rmarkdown.rstudio.com/articles_intro.html), a text format that combines text and code and can be run easily in R Studio and other environments. I also tend to use *ggplot* for plotting, so have look [here](https://ggplot2-book.org) for the low-down on that package.


# Acquiring data

The data come from the [Paleobiology Database](https://paleobiodb.org/#/) (PBDB). Occurrences are downloaded though their [API](https://paleobiodb.org/data1.2/).

First we can download the data as a JSON file and save this to disc: this is our master data set. For this, I've gathered occurrences of Bivalvia from the Cretaceous and Paleogene with all of the occurrence, geographical, systematic, and ecological data.

```{r download_pbdb_data, eval = FALSE}
bivalve_pbdb_url <-
  paste0(
    "https://paleobiodb.org/data1.2/", # PBDB API URL
    "occs/", # occurrences
    "list.json?", # download a JSON file
    "base_name=Bivalvia&", # download bivalve occurrences
    "interval=Cretaceous,Paleogene&", # temporal range to include
    "show=full" # include full data
  )
bivalve_pbdb_file <- paste0(Sys.Date(), "-bivalve_pbdb_occurrences.json")
download.file(bivalve_pbdb_url, bivalve_pbdb_file, method = "curl")
```

The data file can then be loaded into R, which gives a list with length two: the first element (`$elapsed_time`) gives the original download time and the second element (`$records`) is a `data.frame` of the PBDB occurrence data. We keep just this second part. To save space, I've downloaded a version and stored this as a compressed `tar` file that needs to be expanded first with `untar`.

```{r read_pbdb_data}
bivalve_pbdb_file <- "2022-03-18-bivalve_pbdb_occurrences"
untar(paste0(bivalve_pbdb_file, ".tgz"))
bivalve_pbdb_data <- jsonlite::fromJSON(paste0(bivalve_pbdb_file, ".json"))$records %>%
  as_tibble()
```

We won't need data from all the columns, but the important few are:

* `oid`: occurrence ID, a unique reference number.
* `idn`: the originally identified name.
* `tna`: the currently accepted name.
* `rnk`: taxonomic rank of the accepted name.
* `oei`, `oli`: earliest and latest occurrence interval names.
  - `eag` and `lag` are ages at the beginning and end of these intervals, taken from the [*Geologic Time Scale*](https://timescalecreator.org/index/index.php), but may want to update to a recent version.
* `fml`: family of the occurring taxon.
  - higher taxon levels are also included.
* `lng`, `lat`: modern longitude and latitude of the occurrence.
  - `pln` and `pln` are the reconstructed palaeocoordinates, but it may be worth re-doing these to confirm or with a different tectonic model.
* `env`: the palaeoenvironment, useful to check localities and habitats, exclude freshwater species etc. 
* Various [palaeocological/ecospace data](https://paleobiodb.org/data1.2/general/ecotaph_doc.html#Ecospace), such as habitat depth (`jlh`), general environment (`jev`), feeding mode (`jdt`).
* `jco`: composition/mineralogy of shells.

A full list of the fields is at the bottom of [this page](https://paleobiodb.org/data1.2/occs/list_doc.html#response).

# Querying data #

It's a good check to have a quick look at the data to check its size and what different values are contained within. Most of the PBDB data are categorical or strings, which makes it a little more difficult (you can't plot a bar chart for instance, except you can). A few things to check:

* How many records are identified to species level? genus? family?
* How many different species/genera/families are include?
* How many records don't have accepted values?

```{r check_species}
bivalve_pbdb_data %>%
  filter(rnk == 3) %>%
  group_by(tna) %>%
  summarize(n())
```

Or a more fun thing to plot the occurrences from different families.

```{r plot_family_occurrences}
family_occurrences <-
  bivalve_pbdb_data %>%
    filter(rnk == c(3, 4, 5)) %>%
    group_by(fml) %>%
    summarize(family_occurrences = n())
family_occurrences %>%
  ggplot(aes(x = reorder(fml, desc(family_occurrences)), y = family_occurrences)) +
    geom_col()
family_occurrences %>%
  slice_max(family_occurrences, n = 10)
```

## Data quality ##

Now we can do a more thorough look through the data to check that it's correct, or at least in the form we expect it to be. First is the relatively easy one: checking for numbers in columns that should have the, such as rnk, lng, and lat. On import this column is started as a character string in the tibble. We can check whether any of the records are not proper numbers by searching for characters not found in a number: i.e. not digits, decimal points, or minus signs.

```{r data_cleaning}
# search for strings that don't contain a digit, full stop/decimal point, or hyphen/minus, i.e. those that aren't a number
number_as_character_regexp <- "[^[[:digit:]]\\.\\-]"

check_numeric_column <- function(column, data) {
  column_vector <- pull(data, column)
  string_match <- str_which(column_vector, number_as_character_regexp)
  if (length(string_match) == 0) {
    print(paste(column, ": All items are (probably) numbers."))
  } else {
    print(paste(column, ": Some items (probably) aren't numbers."))
    string_match
  }
}

c("lng", "lat", "rnk") %>%
  walk(check_numeric_column, data = bivalve_pbdb_data)
```

Assuming this above comes out tickety-boo, then we can simply replace and reformat those columns to numeric values. It's always a good plan to create a new object doing this so that you don't lose the original data, just in case things go wrong later.

```{r reformatting_numeric_data}
bivalve_cleaned <-
  bivalve_pbdb_data %>%
  mutate(across(c(rnk, lng, lat), as.numeric))
```

The same should be done for the columns we expect to have character strings in, i.e. the accepted name and family column.


# Mapping data #

We can also do more fun things like plot the occurrences on a map. Useful guides to this are found in three blog posts [starting here](https://r-spatial.org//r/2018/10/25/ggplot2-sf.html). Working with mapping data is more involved than simple points, particularly if you want to change the projection away from the standard Mercator. The package `sf` (short for 'simple features', describing how the data is stored) can deal with all of this and then in plotting the projection can be changed. A rule of thumb is make sure to assign the coordinate reference system (CRS) when creating map objects.

Package `rnaturalearth` has regularly updated maps that should be better to use than in the built-in `maps` library. Here we download the country outlines in *sf* format.

```{r map_occurrences}
world_map <-
  ne_countries(returnclass = "sf")
```

Next, convert the occurrences locations into an *sf* object also. I've filtered down to occurrences identified to species level and then taken a random sample ('slice') of 1000 rows. The final stage is convert to an *sf* object using the longitude and latitude columns, with the standard WGS84 CRS (indicated with `4326` in this case). You can find this code to use looking at [epsg.io](https://epsg.io/4326), searching for the projection, and using the code given. In the case of WGS84 coordinates (standard latitude and longitude) shown this is 4326.

```{r get_occurrence_points}
occurrences_to_plot <-
  bivalve_cleaned %>%
  filter(rnk == 3) %>%
  slice_sample(n = 1000) %>%
  st_as_sf(coords = c("lng", "lat"), crs = 4326, agr = "constant")
```

Now, we put these together into the plot using the `geom_sf` function to build up the layers: map outline first, then points over the top. The colour scale is good for colour-blind people, so is a good option to prefer. Here I modify the map projection using `coord_sf(crs)` into the Mollweide projection. I need to work out about adding a border and grid lines at this point.

```{r plot_occurrence_map}
ggplot() +
  geom_sf(data = world_map, inherit.aes = FALSE) +
  geom_sf(data = occurrences_to_plot, mapping = aes(colour = fml)) +
  scale_colour_viridis(discrete = TRUE) +
  coord_sf(crs = "+proj=moll") +
  theme_map() +
  theme(
    legend.position = "none",
  )
```

# Things to do #

* Look at the quality of the data: how many families? which ones are now extinct?
* Can you identify occurrences that have erroneous names? 
* What species go extinct across the Cretaceousâ€“Palaeogene boundary?
* Have a look at [this GitHub repository](https://github.com/benjaminmoon/palaeomap_example) showing how to get data and plot palaeogeographical maps. Can you do the same for occurrences in the Cretaceous and Palaeogene.
